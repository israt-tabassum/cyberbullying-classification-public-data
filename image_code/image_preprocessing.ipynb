{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puM-WjFEO7BS","executionInfo":{"status":"ok","timestamp":1711663743193,"user_tz":-60,"elapsed":438698,"user":{"displayName":"Israt Tabassum","userId":"03898431593025995993"}},"outputId":"426b6f06-6d2b-4bbc-c68a-770c666fcf51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torchvision import datasets, transforms\n","import torchvision.transforms.functional as TF\n","from PIL import Image\n","from random import choice\n","from collections import Counter\n","\n","# Import required for DataLoader\n","from torch.utils.data import DataLoader\n","from PIL import ImageFile\n","\n","# Import required for mounting Google Drive (specific to Google Colab)\n","from google.colab import drive\n","\n","# Mount Google Drive (specific to Google Colab)\n","drive.mount('/content/drive')\n","\n","base_path = '/content/drive/My Drive/Colab Notebooks/public-data/image/dataset'\n","\n","def analyze_dataset(path):\n","    class_counts = Counter()\n","    for class_dir in os.listdir(path):\n","        class_path = os.path.join(path, class_dir)\n","        if os.path.isdir(class_path):\n","            count = len([img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","            class_counts[class_dir] = count\n","    return class_counts\n","\n","def random_transform(image):\n","    \"\"\"Apply random transformations to an image.\"\"\"\n","    image = image.convert(\"RGB\")\n","    if torch.rand(1) > 0.5:\n","        image = TF.hflip(image)\n","    if torch.rand(1) > 0.5:\n","        image = TF.vflip(image)\n","    angle = torch.randint(-30, 30, (1,)).item()\n","    image = TF.rotate(image, angle)\n","    return image\n","\n","def balance_dataset(path, class_counts, max_per_class):\n","    for class_dir in class_counts.keys():\n","        class_path = os.path.join(path, class_dir)\n","        images = [img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","        while len(images) < max_per_class:\n","            img_to_copy = choice(images)\n","            img_path = os.path.join(class_path, img_to_copy)\n","            with Image.open(img_path) as img:\n","                new_img = random_transform(img)\n","                new_img_name = f\"aug_{len(images)}_{img_to_copy}\"\n","                new_img.save(os.path.join(class_path, new_img_name))\n","            images.append(new_img_name)\n","\n","classes = ['0', '1', '2', '3']  # List of class names\n","\n","# Analyze and balance dataset\n","class_counts = analyze_dataset(base_path)\n","max_per_class = max(class_counts.values())\n","balance_dataset(base_path, class_counts, max_per_class)\n","\n","# Define paths for train, validation, and test sets\n","train_path = os.path.join(base_path, 'train')\n","val_path = os.path.join(base_path, 'val')\n","test_path = os.path.join(base_path, 'test')\n","\n","# Create directories for train, validation, and test sets\n","for _class in classes:\n","    os.makedirs(os.path.join(train_path, _class), exist_ok=True)\n","    os.makedirs(os.path.join(val_path, _class), exist_ok=True)\n","    os.makedirs(os.path.join(test_path, _class), exist_ok=True)\n","\n","train_size = 0.8  # 80% for training\n","\n","# Split and move images\n","for _class in classes:\n","    class_dir = os.path.join(base_path, _class)\n","    images = [img for img in os.listdir(class_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","\n","    if not images:\n","        print(f\"No images found in class {_class} directory.\")\n","        continue\n","\n","    train_imgs, non_train_imgs = train_test_split(images, test_size=1 - train_size, random_state=42)\n","    test_imgs, val_imgs = train_test_split(non_train_imgs, test_size=0.5, random_state=42)\n","\n","    for img in train_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(train_path, _class, img))\n","    for img in val_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(val_path, _class, img))\n","    for img in test_imgs:\n","        shutil.move(os.path.join(class_dir, img), os.path.join(test_path, _class, img))\n","\n","# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","# Load datasets\n","train_dataset = datasets.ImageFolder(train_path, transform=transform)\n","val_dataset = datasets.ImageFolder(val_path, transform=transform)\n","test_dataset = datasets.ImageFolder(test_path, transform=transform)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n"]}]}
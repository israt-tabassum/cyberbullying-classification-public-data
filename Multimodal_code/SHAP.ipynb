{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaForSequenceClassification, RobertaTokenizer, ViTForImageClassification, ViTImageProcessor\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set Tesseract path\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# Load RoBERTa tokenizer (common for both models)\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Load ViT model\n",
        "vit_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=4)\n",
        "\n",
        "# Load RoBERTa model\n",
        "text_model = TFRobertaForSequenceClassification.from_pretrained('/content/drive/My Drive/Colab Notebooks/public-data/models/roberta-cyberbullying-classifier')\n",
        "\n",
        "# Load Image model\n",
        "image_model_path = '/content/drive/My Drive/Colab Notebooks/public-data/models/my_vit_model.pth'\n",
        "vit_model.load_state_dict(torch.load(image_model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "# Define function to preprocess the image\n",
        "def preprocess_final(im):\n",
        "    im = cv2.bilateralFilter(im, 5, 55, 60)\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    _, im = cv2.threshold(im, 240, 255, 1)\n",
        "    return im\n",
        "\n",
        "# Define function to extract text from an image\n",
        "def extract_text(image_path, custom_config=r\"--oem 3 --psm 11 -c tessedit_char_whitelist= 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = preprocess_final(img)\n",
        "    text = pytesseract.image_to_string(img, lang='eng', config=custom_config)\n",
        "    return text.replace('\\n', ' ')\n",
        "\n",
        "# Define function to classify text using RoBERTa\n",
        "def classify_text(text):\n",
        "    inputs = roberta_tokenizer.encode_plus(\n",
        "        text, add_special_tokens=True, max_length=512,\n",
        "        padding='max_length', truncation=True, return_tensors=\"tf\"\n",
        "    )\n",
        "    roberta_prediction = text_model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    roberta_probs = tf.nn.softmax(roberta_prediction.logits, axis=1)\n",
        "    text_class = np.argmax(roberta_probs, axis=1)[0]\n",
        "    return text_class\n",
        "\n",
        "# Define function to classify image using ViT\n",
        "def classify_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = vit_processor(images=image, return_tensors=\"pt\")['pixel_values']\n",
        "    with torch.no_grad():\n",
        "        outputs = vit_model(input_tensor)\n",
        "        vit_probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        image_class = torch.argmax(vit_probs, dim=1).item()\n",
        "    return image_class\n",
        "\n",
        "# Define function for late fusion\n",
        "def late_fusion(text_class, image_class):\n",
        "    if text_class == image_class:\n",
        "        if text_class == 0:\n",
        "            return \"Input does not contain any Cyber-bullying.\"\n",
        "        else:\n",
        "            return f\"Input contains this class {text_class} of cyberbullying.\"\n",
        "    else:\n",
        "        return f\"Input contains cyberbullying. Text label is: {text_class} and Image label is: {image_class}\"\n",
        "\n",
        "# Main function to handle input and perform classification\n",
        "def process_input(image_path):\n",
        "    extracted_text = extract_text(image_path)\n",
        "    if extracted_text:\n",
        "        text_class = classify_text(extracted_text)\n",
        "    else:\n",
        "        text_class = None\n",
        "    image_class = classify_image(image_path)\n",
        "    if text_class is not None:\n",
        "        fusion_message = late_fusion(text_class, image_class)\n",
        "    else:\n",
        "        fusion_message = \"No text found to classify.\"\n",
        "\n",
        "    # SHAP explanation for text classification\n",
        "    text_shap_values = explain_text_with_shap(extracted_text)\n",
        "\n",
        "    # SHAP explanation for image classification\n",
        "    image_shap_values = explain_image_with_shap(image_path)\n",
        "\n",
        "    return {\n",
        "        'extracted_text': extracted_text,\n",
        "        'text_label': f\"Text label: {text_class}\" if text_class is not None else \"No text prediction\",\n",
        "        'image_label': f\"Image label: {image_class}\",\n",
        "        'fusion_message': fusion_message,\n",
        "        'text_shap_values': text_shap_values,\n",
        "        'image_shap_values': image_shap_values\n",
        "    }\n",
        "\n",
        "# Function to explain text predictions using SHAP\n",
        "def explain_text_with_shap(text):\n",
        "    # Prepare data for SHAP\n",
        "    inputs = roberta_tokenizer.encode_plus(\n",
        "        text, add_special_tokens=True, max_length=512,\n",
        "        padding='max_length', truncation=True, return_tensors=\"tf\"\n",
        "    )\n",
        "\n",
        "    # Create SHAP explainer for the text classification model\n",
        "    explainer = shap.Explainer(text_model, inputs['input_ids'])\n",
        "    shap_values = explainer(inputs['input_ids'])\n",
        "\n",
        "    # Visualize the SHAP values\n",
        "    shap.initjs()\n",
        "    shap.visualize(shap_values[0])\n",
        "    return shap_values\n",
        "\n",
        "# Function to explain image predictions using SHAP\n",
        "def explain_image_with_shap(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = vit_processor(images=image, return_tensors=\"pt\")['pixel_values']\n",
        "\n",
        "    # Create SHAP explainer for the image classification model\n",
        "    explainer = shap.Explainer(vit_model, input_tensor)\n",
        "    shap_values = explainer(input_tensor)\n",
        "\n",
        "    # Visualize the SHAP values for image\n",
        "    shap.initjs()\n",
        "    shap.visualize(shap_values[0])\n",
        "    return shap_values\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/drive/My Drive/Colab Notebooks/public-data/image/net/test.jpg'\n",
        "results = process_input(image_path)\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "hA_BoMtyir5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}